# Copyright 2022 Observational Health Data Sciences and Informatics
#
# This file is part of DiscoverySystemSimulator
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# library(dplyr)
# library(purrr)
# simulation <- readRDS(file.path(simulationsFolder, "Simulation_i1.rds"))
# cacheFolder <- file.path(simulationsFolder, "Cache_i1")

#' Create setting for the discovery system
#'
#' @param alpha                The family-wise type 1 error rate we're aiming for. Can be a grid of values.
#' @param databaseIdsToIgnore  A list of database IDs to ignore (first database has ID 1, second 2, etc.).
#' @param methodIdsToIgnore    A list of method IDs to ignore (first method has ID 1, method 2, etc.).
#'
#' @return
#' A settings object
#'
#' @export
createDiscoverySystemSettings <- function(alpha = exp(seq(log(0.05), log(5), length.out = 10)),
                                          databaseIdsToIgnore = c(),
                                          methodIdsToIgnore = c()) {
  settings <- list()
  for (name in names(formals(createDiscoverySystemSettings))) {
    settings[[name]] <- get(name)
  }
  return(settings)
}


#' Run discovery system
#'
#' @param simulation              An object generated by [simulateDiscoverySystem()].
#' @param discoverySystemSettings An object generated by [createDiscoverySystemSettings()].
#' @param cacheFolder             Optionally, a folder where intermediate artifacts (e.g. fitted
#'                                systematic error distributions) can be cached. If `NULL`, no
#'                                caching is performed.
#' @param cvCacheFile             Optionally, the name of a global cache file for critical values.
#'                                If `NULL`, no caching is performed.
#'
#' @return
#' Returns a tibble with signal flags for each row in the simulation.
#'
#' @export
runDiscoverySystem <- function(simulation = simulateDiscoverySystem(),
                               discoverySystemSettings = createDiscoverySystemSettings(),
                               cacheFolder = NULL,
                               cvCacheFile = NULL) {
  if (!is.null(cacheFolder) && !dir.exists(cacheFolder)) {
    message(sprintf("Folder '%s' does not exist, so creating it.", cacheFolder))
    dir.create(cacheFolder, recursive = TRUE)
  }
  if (length(discoverySystemSettings$databaseIdsToIgnore) > 0) {
    message(sprintf("Removing database ID(s) %s from the simulation.",
                    paste(discoverySystemSettings$databaseIdsToIgnore, collapse = ",")))
    simulation <- simulation %>%
      filter(!.data$databaseId %in% discoverySystemSettings$databaseIdsToIgnore)
  }
  if (length(discoverySystemSettings$methodIdsToIgnore) > 0) {
    message(sprintf("Removing method ID(s) %s from the simulation.",
                    paste(discoverySystemSettings$methodIdsToIgnore, collapse = ",")))
    simulation <- simulation %>%
      filter(!.data$methodId %in% discoverySystemSettings$methodIdsToIgnore)
  }

  # Divide alpha over exposure-outcomes (Bonferroni)
  nExposureOutcomes <- simulation %>%
    distinct(.data$exposureOutcomeId) %>%
    count() %>%
    pull()

  alphaPerExposureOutcome <- tibble(alpha = discoverySystemSettings$alpha,
                                    alphaPerExposureOutcome = discoverySystemSettings$alpha / nExposureOutcomes)

  # Divide alpha over databases (Bonferroni)
  alphaPerDatabase <- simulation %>%
    group_by(.data$exposureOutcomeId) %>%
    distinct(.data$databaseId) %>%
    count(name = "nDatabases") %>%
    inner_join(alphaPerExposureOutcome, by = character()) %>%
    mutate(alphaPerDatabase = .data$alphaPerExposureOutcome / .data$nDatabases)

  # Divide alpha over time at risks (Bonferroni)
  alphaPerTar <- simulation %>%
    group_by(.data$exposureOutcomeId, .data$databaseId) %>%
    distinct(.data$timeAtRiskId) %>%
    count(name = "nTars") %>%
    inner_join(alphaPerDatabase, by = "exposureOutcomeId") %>%
    mutate(alphaPerTar = .data$alphaPerDatabase / .data$nTars) %>%
    ungroup()

  # Divide alpha over methods (Bonferroni)
  alphaPerMethod <- simulation %>%
    group_by(.data$exposureOutcomeId, .data$databaseId, .data$timeAtRiskId) %>%
    distinct(.data$methodId) %>%
    count(name = "nMethods") %>%
    inner_join(alphaPerTar, by = c("exposureOutcomeId", "databaseId")) %>%
    mutate(alphaPerMethod = .data$alphaPerTar / .data$nMethods) %>%
    ungroup()

  # Calibrated MaxSPRT
  signals <- performCalibratedMaxSprt(simulation = simulation,
                                      alphaPerMethod = alphaPerMethod,
                                      discoverySystemSettings = discoverySystemSettings,
                                      cacheFolder = cacheFolder,
                                      cvCacheFile = cvCacheFile)
  return(signals)
}

performCalibratedMaxSprt <- function(simulation,
                                     alphaPerMethod,
                                     discoverySystemSettings,
                                     cacheFolder,
                                     cvCacheFile) {
  distributions <- fitSystematicErrorDistributions(simulation, cacheFolder)

  calibratedPs <- computeCalibratedPs(simulation, distributions)

  criticalValues <- computeCriticalValues(simulation, alphaPerMethod, distributions, cvCacheFile)

  data <- calibratedPs %>%
    select(.data$methodId,
           .data$timeAtRiskId,
           .data$exposureOutcomeId,
           .data$databaseId,
           .data$lookId,
           .data$p,
           .data$calibratedP,
           .data$llr,
           .data$logRr,
           .data$seLogRr,
           .data$profileIdx) %>%
    inner_join(criticalValues, by = c("methodId", "timeAtRiskId", "exposureOutcomeId", "databaseId", "lookId")) %>%
    inner_join(distributions, by = c("methodId", "timeAtRiskId", "databaseId", "lookId")) %>%
    inner_join(alphaPerMethod, by = c("timeAtRiskId", "exposureOutcomeId", "databaseId", "alphaPerMethod"))

  message("Computing signals")
  # row <- split(data, seq_len(nrow(data)))[[1]]
  computeSignals <- function(row) {
    row %>%
      mutate(signalMaxSprt = .data$llr > .data$cv,
             signalCalibratedMaxSprt = .data$llr > .data$calibratedCv,
             signalP = if_else(is.na(.data$p), FALSE, .data$p < row$alphaPerMethod),
             signalCalibratedP = if_else(is.na(.data$calibratedP), FALSE, .data$calibratedP < row$alphaPerMethod)) %>%
      return()
  }
  signals <- map_dfr(split(data, seq_len(nrow(data))), computeSignals)

  signals <- signals %>%
    select(.data$methodId,
           .data$timeAtRiskId,
           .data$exposureOutcomeId,
           .data$databaseId,
           .data$lookId,
           .data$alpha,
           .data$signalMaxSprt,
           .data$signalCalibratedMaxSprt,
           .data$signalP,
           .data$cvAlpha,
           .data$signalCalibratedP,
           .data$calibratedCvAlpha) %>%
    dropNonStandardAttributes()
  return(signals)
}

computeCalibratedPs <- function(simulation, distributions) {
  groups <- simulation %>%
    inner_join(distributions, by = c("methodId", "timeAtRiskId", "databaseId", "lookId")) %>%
    group_by(.data$systematicErrorMean , .data$systematicErrorSd) %>%
    group_split()

  calibrateP <- function(group) {
    null <- c(group$systematicErrorMean[1], group$systematicErrorSd[1])
    class(null) <- "null"
    calibratedP <- EmpiricalCalibration::calibrateP(null = null, logRr = group$logRr, seLogRr = group$seLogRr, twoSided = FALSE, upper = TRUE)
    group %>%
      mutate(calibratedP = !!calibratedP) %>%
      return()
  }
  results <- map_dfr(groups, calibrateP) %>%
    select(-.data$systematicErrorMean,
           -.data$systematicErrorSd)
  return(results)
}

dropNonStandardAttributes <- function(object) {
  standard <- names(attributes(tibble()))
  attributes(object) <- attributes(object)[standard]
  return(object)
}

fitSystematicErrorDistributions <- function(simulation, cacheFolder) {
  if (!is.null(cacheFolder)) {
    cacheFile <- file.path(cacheFolder, "SystematicErrorDistributions.rds")
    cache <- TRUE
  } else {
    cache <- FALSE
  }

  if (cache && file.exists(cacheFile)) {
    distributions <- readRDS(cacheFile)
  } else {
    # Using all simulated exposure-outcome pairs with null effect as negative controls:
    negativeControlIds <- getNegativeControlIds(attr(simulation, "simulationSettings"))

    message("Fitting systematic error distributions")
    # subset <- split(simulation, paste(simulation$databaseId, simulation$timeAtRiskId, simulation$methodId, simulation$lookId))[[1]]
    fitDistribution <- function(subset) {
      negativeControls <- subset %>%
        filter(.data$exposureOutcomeId %in% negativeControlIds)
      # Option: could also fit using normal approximation on per-control likelihood
      profiles <- attr(simulation, "profiles")[negativeControls$profileIdx]
      profiles <- profiles %>%
        discard(is.null)
      suppressMessages(
        distribution <- EmpiricalCalibration::fitNullNonNormalLl(profiles)
      )
      tibble(databaseId = subset$databaseId[1],
             timeAtRiskId = subset$timeAtRiskId[1],
             methodId = subset$methodId[1],
             lookId = subset$lookId[1],
             systematicErrorMean = distribution[1],
             systematicErrorSd = distribution[2]) %>%
        return()
    }
    distributions <- map_dfr(split(simulation, paste(simulation$databaseId,
                                                     simulation$timeAtRiskId,
                                                     simulation$methodId,
                                                     simulation$lookId)),
                             fitDistribution)
    if (cache) {
      saveRDS(distributions, cacheFile)
    }
  }
  return(distributions)
}

computeCriticalValues <- function(simulation, alphaPerMethod, distributions, cvCacheFile) {
  simulationSettings <- attr(simulation, "simulationSettings")
  exposureOutcomeSettings <- map_dfr(simulationSettings$exposureOutcomeSettings,
                                     function(x) return(tibble(z = x$nComparator / x$nTarget,
                                                               expectedEventsPerDay = x$backgroundRate * (x$nComparator + x$nTarget)))) %>%
    mutate(exposureOutcomeId = row_number())
  databaseSettings <- map_dfr(simulationSettings$databaseSettings,
                              function(x) return(tibble(sampleSizeMultiplier = x$sampleSizeMultiplier))) %>%
    mutate(databaseId = row_number())
  timeAtRiskSettings <- map_dfr(simulationSettings$timeAtRiskSettings,
                                function(x) return(tibble(start = x$start, end = x$end))) %>%
    mutate(timeAtRiskId  = row_number())
  values <- alphaPerMethod %>%
    inner_join(exposureOutcomeSettings, by = "exposureOutcomeId") %>%
    inner_join(databaseSettings, by = "databaseId") %>%
    inner_join(timeAtRiskSettings, by = "timeAtRiskId") %>%
    inner_join(distributions, by = c("databaseId", "timeAtRiskId")) %>%
    mutate(expectedEventsPerLook = .data$expectedEventsPerDay * .data$sampleSizeMultiplier * (.data$end - .data$start + 1),
           looks = simulationSettings$looks)
  uniqueValuesForCv <- values %>%
    distinct(.data$expectedEventsPerLook, .data$looks, .data$z, alpha = .data$alphaPerMethod) %>%
    mutate(systematicErrorMean = 0,
           systematicErrorSd = 0)
  uniqueValuesForCalibratedCv <- values %>%
    distinct(.data$expectedEventsPerLook, .data$looks, .data$z, alpha = .data$alphaPerMethod, .data$systematicErrorMean , .data$systematicErrorSd)
  cvsToCompute <- bind_rows(uniqueValuesForCalibratedCv, uniqueValuesForCv) %>%
    mutate(model = "binomial")


  message("Computing critical values")
  cvs <- computeCriticalValuesWithCache(cvsToCompute, cvCacheFile)

  uncalibratedCvs <- uniqueValuesForCv %>%
    inner_join(cvs, by = c("alpha", "z", "expectedEventsPerLook", "looks", "systematicErrorMean", "systematicErrorSd")) %>%
    select(-.data$systematicErrorMean,
           -.data$systematicErrorSd,
           -.data$model) %>%
    rename(alphaPerMethod = .data$alpha)

  calibratedCvs <- uniqueValuesForCalibratedCv %>%
    inner_join(cvs, by = c("alpha", "z", "systematicErrorMean", "systematicErrorSd", "expectedEventsPerLook", "looks"))  %>%
    select(-.data$model) %>%
    rename(calibratedCv = .data$cv,
           calibratedCvAlpha = .data$cvAlpha) %>%
    rename(alphaPerMethod = .data$alpha)

  criticalValues <- values %>%
    inner_join(uncalibratedCvs, by = c("alphaPerMethod", "z", "expectedEventsPerLook", "looks")) %>%
    inner_join(calibratedCvs, by = c("alphaPerMethod", "z", "expectedEventsPerLook", "looks", "systematicErrorMean", "systematicErrorSd")) %>%
    select(.data$exposureOutcomeId,
           .data$databaseId,
           .data$timeAtRiskId,
           .data$methodId,
           .data$lookId,
           .data$alphaPerMethod,
           .data$cv,
           .data$cvAlpha,
           .data$calibratedCv,
           .data$calibratedCvAlpha)

  return(criticalValues)
}
